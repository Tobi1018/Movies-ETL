# Movies-ETL

![image202](https://user-images.githubusercontent.com/58860105/136827367-59396828-6807-4837-b8eb-413a9e1d8fa8.PNG)

Perform the Extract, Transform and Load (ETL) process to create a data pipeline on movie datasets using Python, Pandas, Jupyter Notebook and PostgreSQL.

In this project, I created an automated pipeline that takes in new data, performs the appropriate transformations, and loads the data into existing tables.  Refactored the code from the module challenge and created one function that takes in the three files—Wikipedia data, Kaggle metadata, and the MovieLens rating data—and performs the ETL process by adding the data to a PostgreSQL database.


## Deliverable 1

Using knowledge of Python, Pandas, the ETL process, and code refactoring, write a function that reads in the three data files and creates three separate DataFrames

Wiki_movies_df DataFrame

![movies df](https://user-images.githubusercontent.com/58860105/136827910-390a2a98-4eb4-4ac6-90e3-15ed95d817b7.PNG)


kaggle_metadata DataFrame

![kaggledf](https://user-images.githubusercontent.com/58860105/136828042-b5e60f03-d663-4a21-8a82-5594a9938088.PNG)
